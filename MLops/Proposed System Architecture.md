| **Component**       | **What It Is**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | **Who Uses It**                                                                                                                                              | **Functionality**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Data Pipeline**    | The Data Pipeline is a set of automated processes that manage the flow of data from the initial source to the final destination, often used in the training of machine learning models. Its components include: <br>- **Data Ingestion**: Collecting data from various sources (databases, APIs, files, real-time streams). <br>- **Data Transformation**: Cleaning, transforming, and normalizing the data, performing feature engineering to ensure that the data is optimized for ML models.<br>- **Data Storage**: Moving transformed data into storage systems such as data lakes or NoSQL databases.                           | Data Engineers, Data Scientists, ML Engineers                                                                                                                | - **Automated ETL**: Automates the process of extracting, transforming, and loading data.<br>- **Data Quality Management**: Ensures that data is clean and consistent before being used in the model.<br>- **Scalability**: Designed to handle large amounts of data with scalable, parallel data streams.<br>- **Integration with Other Tools**: Easily integrates with machine learning tools like TensorFlow, PyTorch, or data management systems like Apache Spark.<br>- **Data Processing Scheduling**: Executes ETL processes on a set schedule to always keep the data up to date.                                                                                                                                                                                                                                            |
| **JupyterHub**       | JupyterHub is a multi-user environment that allows multiple data scientists and ML engineers to work on the same notebook platform. It supports real-time model building and training while managing resources and environments for each user. Its main components include: <br>- **Authenticator**: Supports user authentication and authorization.<br>- **Spawner**: Responsible for creating independent notebook environments for each user.<br>- **Hub**: Manages multiple user notebook sessions.<br>- **Kernel**: The environment where code execution happens, supporting multiple languages like Python, R, Julia.      | Data Scientists, ML Engineers                                                                                                                               | - **Collaborative Development Environment**: Allows multiple data scientists to collaborate on projects with access to the same datasets and tools.<br>- **Customizable User Environments**: Each user can have their own notebook environment with different packages and tools, allowing flexibility in research.<br>- **Flexible Resource Allocation**: Supports assigning appropriate CPU/GPU resources for each notebook session to optimize model training performance.<br>- **Session Management**: Tracks and manages user sessions to ensure resources are used efficiently and prevent resource duplication.                                                                                                                                                                                                             |
| **Image Registry**   | The Image Registry (Container Image Repository) is a service that stores Docker or OCI (Open Container Initiative) container images. This is where trained models or containerized applications are stored. The image registry allows managing versions of models and applications and supports easy deployment in production or test environments. Its components include: <br>- **Storage**: Stores images with different versions.<br>- **Tagging**: Labels images with tags to easily manage and track versions.<br>- **Access Control**: Controls who can access the images.                                                        | DevOps Engineers, ML Engineers, Software Engineers                                                                                                           | - **Storing and Managing Container Images**: Allows storing multiple versions of containerized applications and machine learning models. This helps in tracking changes and easily rolling back to a previous version if necessary.<br>- **Version Control**: Supports tagging images to easily distinguish between different versions, making it easier to manage and deploy specific versions as needed.<br>- **CI/CD Integration**: The image registry integrates with CI/CD pipelines to automate the deployment of the latest containers into production environments.<br>- **Enhanced Security**: The image registry can integrate with security measures like vulnerability scanning and access management to protect container images from attacks or exploitations.                                                                                                                                              |
